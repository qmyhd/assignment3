{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "file_path = 'C:\\\\Users\\\\qaism\\\\OneDrive - University of Virginia\\\\Documents\\\\GitHub\\\\assignment3\\\\data\\\\car_data.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   User ID Gender  Age  AnnualSalary  Purchased\n",
      "0      385   Male   35         20000          0\n",
      "1      681   Male   40         43500          0\n",
      "2      353   Male   49         74000          0\n",
      "3      895   Male   40        107500          1\n",
      "4      661   Male   25         79000          0\n",
      "Shape of the dataset:\n",
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"Shape of the dataset:\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "           User ID          Age   AnnualSalary    Purchased\n",
      "count  1000.000000  1000.000000    1000.000000  1000.000000\n",
      "mean    500.500000    40.106000   72689.000000     0.402000\n",
      "std     288.819436    10.707073   34488.341867     0.490547\n",
      "min       1.000000    18.000000   15000.000000     0.000000\n",
      "25%     250.750000    32.000000   46375.000000     0.000000\n",
      "50%     500.500000    40.000000   72000.000000     0.000000\n",
      "75%     750.250000    48.000000   90000.000000     1.000000\n",
      "max    1000.000000    63.000000  152500.000000     1.000000\n",
      "Missing Values:\n",
      "User ID         0\n",
      "Gender          0\n",
      "Age             0\n",
      "AnnualSalary    0\n",
      "Purchased       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Summarize the variables\n",
    "summary_stats = df.describe()\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Convert Gender into a dummy variable\n",
    "df['Gender'] = df['Gender'].apply(lambda x: 0 if x == 'Male' else 1)\n",
    "\n",
    "# Create a matrix X of predictors and an outcome y\n",
    "X = df[['Age', 'AnnualSalary']]\n",
    "y = df['Purchased']\n",
    "\n",
    "print(\"Summary Statistics:\")\n",
    "print(summary_stats)\n",
    "\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 800\n",
      "Number of samples in testing set: 200\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data in 'X'\n",
    "X_normalized = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "# Show the number of samples in the training and testing sets\n",
    "print(\"Number of samples in training set:\", len(X_train))\n",
    "print(\"Number of samples in testing set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxMin-normalize Age and AnnualSalary\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)# Determine the optimal number of neighbors using GridSearchCV\n",
    "params = {'n_neighbors': range(1, 20)}\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn, params, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the optimal number of neighbors\n",
    "optimal_neighbors = grid_search.best_params_['n_neighbors']\n",
    "\n",
    "# Initialize the KNeighborsClassifier with the optimal number of neighbors\n",
    "knn_optimal = KNeighborsClassifier(n_neighbors=optimal_neighbors)\n",
    "\n",
    "# Fit the model to the scaled training data\n",
    "knn_optimal.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the scaled test set\n",
    "y_pred = knn_optimal.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[102  10]\n",
      " [ 30  58]]\n",
      "Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the KNeighborsClassifier with the optimal number of neighbors\n",
    "knn_optimal = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn_optimal.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn_optimal.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix\n",
    "True Negative (TN): 102 - The model correctly predicted that a sale would not occur 102 times.\n",
    "False Positive (FP): 10 - The model incorrectly predicted a sale 10 times when it did not actually occur.\n",
    "False Negative (FN): 30 - The model incorrectly predicted no sale 30 times when a sale actually did occur.\n",
    "True Positive (TP): 58 - The model correctly predicted that a sale would occur 58 times.\n",
    "\n",
    "Accuracy\n",
    "The accuracy of your model is 0.80 or 80, which is pretty good for a classification problem.\n",
    "\n",
    "Interpretation\n",
    "The model predicts a sale when one fails to occur in 10 cases (FP).\n",
    "The model predicts no sale when one does occur in 30 cases (FN).\n",
    "Overall, the model provides accurate predictions 80 of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_df_men: (98, 4)\n",
      "Shape of test_df_women: (102, 4)\n",
      "Confusion Matrix for Men: [[57  3]\n",
      " [16 22]]\n",
      "Accuracy for Men: 0.8061224489795918\n",
      "Confusion Matrix for Women: [[45  7]\n",
      " [14 36]]\n",
      "Accuracy for Women: 0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "# Convert Gender into a dummy variable\n",
    "test_df['Gender'] = test_df['Gender'].apply(lambda x: 0 if x == 'Male' else 1)\n",
    "\n",
    "# Separate men and women in the test dataset\n",
    "test_df_men = test_df[test_df['Gender'] == 0]\n",
    "test_df_women = test_df[test_df['Gender'] == 1]\n",
    "\n",
    "# Now check the shape again\n",
    "print(\"Shape of test_df_men:\", test_df_men.shape)\n",
    "print(\"Shape of test_df_women:\", test_df_women.shape)\n",
    "# Separate X and y for men and women\n",
    "X_test_men = test_df_men[['Age', 'AnnualSalary']]\n",
    "y_test_men = test_df_men['Purchased']\n",
    "\n",
    "X_test_women = test_df_women[['Age', 'AnnualSalary']]\n",
    "y_test_women = test_df_women['Purchased']\n",
    "\n",
    "# Make predictions for men and women separately using the fitted knn_optimal model\n",
    "y_pred_men = knn_optimal.predict(X_test_men)\n",
    "y_pred_women = knn_optimal.predict(X_test_women)\n",
    "\n",
    "# Compute confusion matrices and accuracy scores\n",
    "conf_matrix_men = confusion_matrix(y_test_men, y_pred_men)\n",
    "conf_matrix_women = confusion_matrix(y_test_women, y_pred_women)\n",
    "\n",
    "accuracy_men = accuracy_score(y_test_men, y_pred_men)\n",
    "accuracy_women = accuracy_score(y_test_women, y_pred_women)\n",
    "\n",
    "print(\"Confusion Matrix for Men:\", conf_matrix_men)\n",
    "print(\"Accuracy for Men:\", accuracy_men)\n",
    "print(\"Confusion Matrix for Women:\", conf_matrix_women)\n",
    "print(\"Accuracy for Women:\", accuracy_women)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's accuracy for predicting purchases is approximately 80.6% for men and 79.4% for women. The differences in accuracy between the two groups are relatively small, suggesting that the model performs similarly for both men and women."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
